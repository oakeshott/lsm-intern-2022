{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "967d1533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import random_split, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from torch_geometric.data import Dataset, InMemoryDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import from_networkx, train_test_split_edges\n",
    "from torch_geometric.nn import global_add_pool, GCNConv\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f3e84cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NetworkMetricsWithTopologyDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "#         self.data_dir = \"../dataset/train/network\"\n",
    "#         self.processed_dir = '/tmp/'\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [filename for filename in sorted(os.listdir(self.raw_dir))]\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "#         data_size = 5969\n",
    "#         data_size = 5333\n",
    "#         return [f'data_{i}.pt' for i in range(data_size)]\n",
    "        return [i  for i in sorted(os.listdir(self.processed_dir)) if 'data' in i]\n",
    "\n",
    "    def process(self):\n",
    "        idx = 0\n",
    "        for raw_path in self.raw_paths:\n",
    "            # Read data from `raw_path`.\n",
    "            g = nx.read_gpickle(raw_path)\n",
    "            for n in g.nodes():\n",
    "                label = g.nodes()[n]['label']\n",
    "                del g.nodes()[n]['label']\n",
    "            data = from_networkx(g)\n",
    "            data.y =  torch.tensor(label)\n",
    "            data.num_nodes = len(g.nodes())\n",
    "            data.edge_attr = []\n",
    "            if self.pre_filter is not None and not self.pre_filter(data):\n",
    "                continue\n",
    "\n",
    "            if self.pre_transform is not None:\n",
    "                data = self.pre_transform(data)\n",
    "\n",
    "            torch.save(data, os.path.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "            idx += 1\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(os.path.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c1ab450",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(GCNClassifier, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        hidden_dim = 128\n",
    "        \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(hidden_dim, self.output_dim),\n",
    "        )\n",
    "        \n",
    "        self.gcn1 = GCNConv(self.input_dim, hidden_dim)\n",
    "        self.gcn2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def forward(self, x, edge_index, batch, edge_attr):\n",
    "        x = self.gcn1(x, edge_index, edge_attr)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.gcn2(x, edge_index, edge_attr)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        return self.linear(global_add_pool(x, batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0d38ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "batchsize = 16\n",
    "max_epoch = 100\n",
    "device = 'cpu'\n",
    "path = \"../dataset/train/network\"\n",
    "model_dir = \"models/gcn\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "metrics = [\"cpu-util\", \"tx-pps\", \"rx-pps\", \"network-incoming-packets-rate\", \"network-outgoing-packets-rate\", \"prefix-activity-received-current-prefixes\"]\n",
    "events = {\n",
    "    'normal': 0,\n",
    "    'ixnetwork-bgp-hijacking-start': 1,\n",
    "    'ixnetwork-bgp-injection-start': 2,\n",
    "    'node-down': 3,\n",
    "    'interface-down': 4,\n",
    "    'packet-loss-delay': 5,\n",
    "}\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "dataset = NetworkMetricsWithTopologyDataset(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9caa88af",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [dataset[i].y for i in range(len(dataset))]\n",
    "train_indices, val_indices = train_test_split(\n",
    "    list(range(len(dataset))),\n",
    "    test_size=0.2,\n",
    "    stratify=labels,\n",
    "    random_state=seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caea50e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[train_indices]\n",
    "train_size = len(train_dataset)\n",
    "val_dataset = dataset[val_indices]\n",
    "val_size = len(val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a919bcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batchsize)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=val_size)\n",
    "\n",
    "\n",
    "input_dim = train_dataset[0].x.shape[-1]\n",
    "output_dim = len(events.keys())\n",
    "model =GCNClassifier(input_dim, output_dim).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "val_data = iter(val_dataloader).next()\n",
    "val_batch = val_data.batch.to(device)\n",
    "val_edge_index = val_data.edge_index.to(device)\n",
    "val_edge_attr = None\n",
    "val_labels = val_data.y.long().to(device).view(-1)\n",
    "val_data = val_data.x.float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86454490",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: [1/100] train loss: 0.8444 train acc: 0.7401 val loss: 0.6900 val acc: 0.782245\n",
      "EPOCH: [2/100] train loss: 0.6983 train acc: 0.7964 val loss: 0.6073 val acc: 0.824121\n",
      "EPOCH: [3/100] train loss: 0.6508 train acc: 0.8184 val loss: 0.5727 val acc: 0.829146\n",
      "EPOCH: [4/100] train loss: 0.6244 train acc: 0.8232 val loss: 0.5320 val acc: 0.837521\n",
      "EPOCH: [5/100] train loss: 0.5780 train acc: 0.8323 val loss: 0.4993 val acc: 0.845896\n",
      "EPOCH: [6/100] train loss: 0.5383 train acc: 0.8461 val loss: 0.4531 val acc: 0.860134\n",
      "EPOCH: [7/100] train loss: 0.5171 train acc: 0.8501 val loss: 0.4404 val acc: 0.866834\n",
      "EPOCH: [8/100] train loss: 0.4965 train acc: 0.8574 val loss: 0.4277 val acc: 0.868509\n",
      "EPOCH: [9/100] train loss: 0.4892 train acc: 0.8593 val loss: 0.4180 val acc: 0.871859\n",
      "EPOCH: [10/100] train loss: 0.4842 train acc: 0.8612 val loss: 0.4220 val acc: 0.868509\n",
      "EPOCH: [11/100] train loss: 0.4704 train acc: 0.8616 val loss: 0.4080 val acc: 0.873534\n",
      "EPOCH: [12/100] train loss: 0.4647 train acc: 0.8639 val loss: 0.4127 val acc: 0.871859\n",
      "EPOCH: [13/100] train loss: 0.4620 train acc: 0.8618 val loss: 0.4122 val acc: 0.870184\n",
      "EPOCH: [14/100] train loss: 0.4520 train acc: 0.8664 val loss: 0.4075 val acc: 0.872697\n",
      "EPOCH: [15/100] train loss: 0.4461 train acc: 0.8699 val loss: 0.3985 val acc: 0.877722\n",
      "EPOCH: [16/100] train loss: 0.4492 train acc: 0.8666 val loss: 0.3933 val acc: 0.878559\n",
      "EPOCH: [17/100] train loss: 0.4342 train acc: 0.8702 val loss: 0.3892 val acc: 0.879397\n",
      "EPOCH: [18/100] train loss: 0.4459 train acc: 0.8641 val loss: 0.3966 val acc: 0.878559\n",
      "EPOCH: [19/100] train loss: 0.4294 train acc: 0.8706 val loss: 0.3869 val acc: 0.875209\n",
      "EPOCH: [20/100] train loss: 0.4439 train acc: 0.8668 val loss: 0.3820 val acc: 0.881910\n",
      "EPOCH: [21/100] train loss: 0.4279 train acc: 0.8712 val loss: 0.3871 val acc: 0.879397\n",
      "EPOCH: [22/100] train loss: 0.4288 train acc: 0.8702 val loss: 0.3843 val acc: 0.881072\n",
      "EPOCH: [23/100] train loss: 0.4306 train acc: 0.8691 val loss: 0.3853 val acc: 0.877722\n",
      "EPOCH: [24/100] train loss: 0.4179 train acc: 0.8725 val loss: 0.3844 val acc: 0.881072\n",
      "EPOCH: [25/100] train loss: 0.4313 train acc: 0.8689 val loss: 0.3963 val acc: 0.872697\n",
      "EPOCH: [26/100] train loss: 0.4239 train acc: 0.8691 val loss: 0.3806 val acc: 0.879397\n",
      "EPOCH: [27/100] train loss: 0.4168 train acc: 0.8727 val loss: 0.3926 val acc: 0.878559\n",
      "EPOCH: [28/100] train loss: 0.4260 train acc: 0.8737 val loss: 0.3827 val acc: 0.878559\n",
      "EPOCH: [29/100] train loss: 0.4148 train acc: 0.8743 val loss: 0.3879 val acc: 0.873534\n",
      "EPOCH: [30/100] train loss: 0.4158 train acc: 0.8733 val loss: 0.3745 val acc: 0.883585\n",
      "EPOCH: [31/100] train loss: 0.4069 train acc: 0.8756 val loss: 0.3747 val acc: 0.884422\n",
      "EPOCH: [32/100] train loss: 0.4247 train acc: 0.8712 val loss: 0.4335 val acc: 0.876047\n",
      "EPOCH: [33/100] train loss: 0.4120 train acc: 0.8741 val loss: 0.3699 val acc: 0.885260\n",
      "EPOCH: [34/100] train loss: 0.4039 train acc: 0.8779 val loss: 0.3721 val acc: 0.886097\n",
      "EPOCH: [35/100] train loss: 0.4095 train acc: 0.8769 val loss: 0.3746 val acc: 0.885260\n",
      "EPOCH: [36/100] train loss: 0.4066 train acc: 0.8781 val loss: 0.3746 val acc: 0.885260\n",
      "EPOCH: [37/100] train loss: 0.4114 train acc: 0.8769 val loss: 0.3799 val acc: 0.882747\n",
      "EPOCH: [38/100] train loss: 0.4210 train acc: 0.8739 val loss: 0.3688 val acc: 0.885260\n",
      "EPOCH: [39/100] train loss: 0.3981 train acc: 0.8792 val loss: 0.3747 val acc: 0.881910\n",
      "EPOCH: [40/100] train loss: 0.3966 train acc: 0.8792 val loss: 0.3654 val acc: 0.886935\n",
      "EPOCH: [41/100] train loss: 0.4087 train acc: 0.8777 val loss: 0.3793 val acc: 0.881910\n",
      "EPOCH: [42/100] train loss: 0.4136 train acc: 0.8785 val loss: 0.3776 val acc: 0.880235\n",
      "EPOCH: [43/100] train loss: 0.3990 train acc: 0.8790 val loss: 0.3651 val acc: 0.886935\n",
      "EPOCH: [44/100] train loss: 0.3960 train acc: 0.8810 val loss: 0.3684 val acc: 0.885260\n",
      "EPOCH: [45/100] train loss: 0.4031 train acc: 0.8779 val loss: 0.3793 val acc: 0.880235\n",
      "EPOCH: [46/100] train loss: 0.4069 train acc: 0.8762 val loss: 0.3673 val acc: 0.885260\n",
      "EPOCH: [47/100] train loss: 0.3959 train acc: 0.8779 val loss: 0.3759 val acc: 0.884422\n",
      "EPOCH: [48/100] train loss: 0.4054 train acc: 0.8787 val loss: 0.3672 val acc: 0.884422\n",
      "EPOCH: [49/100] train loss: 0.3992 train acc: 0.8787 val loss: 0.3813 val acc: 0.881910\n",
      "EPOCH: [50/100] train loss: 0.3999 train acc: 0.8783 val loss: 0.3731 val acc: 0.883585\n",
      "EPOCH: [51/100] train loss: 0.4076 train acc: 0.8777 val loss: 0.3765 val acc: 0.880235\n",
      "EPOCH: [52/100] train loss: 0.4017 train acc: 0.8785 val loss: 0.3726 val acc: 0.884422\n",
      "EPOCH: [53/100] train loss: 0.3952 train acc: 0.8808 val loss: 0.3644 val acc: 0.885260\n",
      "EPOCH: [54/100] train loss: 0.4057 train acc: 0.8781 val loss: 0.3681 val acc: 0.886097\n",
      "EPOCH: [55/100] train loss: 0.4040 train acc: 0.8764 val loss: 0.3787 val acc: 0.882747\n",
      "EPOCH: [56/100] train loss: 0.4044 train acc: 0.8760 val loss: 0.3697 val acc: 0.884422\n",
      "EPOCH: [57/100] train loss: 0.3950 train acc: 0.8800 val loss: 0.3655 val acc: 0.886097\n",
      "EPOCH: [58/100] train loss: 0.3996 train acc: 0.8800 val loss: 0.3709 val acc: 0.885260\n",
      "EPOCH: [59/100] train loss: 0.3965 train acc: 0.8794 val loss: 0.3702 val acc: 0.884422\n",
      "EPOCH: [60/100] train loss: 0.3982 train acc: 0.8792 val loss: 0.3760 val acc: 0.885260\n",
      "EPOCH: [61/100] train loss: 0.3884 train acc: 0.8819 val loss: 0.3817 val acc: 0.885260\n",
      "EPOCH: [62/100] train loss: 0.3951 train acc: 0.8810 val loss: 0.3835 val acc: 0.881072\n",
      "EPOCH: [63/100] train loss: 0.3971 train acc: 0.8792 val loss: 0.3743 val acc: 0.886097\n",
      "EPOCH: [64/100] train loss: 0.3973 train acc: 0.8806 val loss: 0.3806 val acc: 0.884422\n",
      "EPOCH: [65/100] train loss: 0.3984 train acc: 0.8800 val loss: 0.3795 val acc: 0.885260\n",
      "EPOCH: [66/100] train loss: 0.4018 train acc: 0.8796 val loss: 0.3768 val acc: 0.886097\n",
      "EPOCH: [67/100] train loss: 0.4033 train acc: 0.8785 val loss: 0.3784 val acc: 0.886097\n",
      "EPOCH: [68/100] train loss: 0.3942 train acc: 0.8792 val loss: 0.3749 val acc: 0.884422\n",
      "EPOCH: [69/100] train loss: 0.3984 train acc: 0.8794 val loss: 0.3678 val acc: 0.886097\n",
      "EPOCH: [70/100] train loss: 0.3892 train acc: 0.8813 val loss: 0.3749 val acc: 0.884422\n",
      "EPOCH: [71/100] train loss: 0.3867 train acc: 0.8817 val loss: 0.3689 val acc: 0.885260\n",
      "EPOCH: [72/100] train loss: 0.3882 train acc: 0.8813 val loss: 0.3713 val acc: 0.885260\n",
      "EPOCH: [73/100] train loss: 0.3825 train acc: 0.8821 val loss: 0.3793 val acc: 0.884422\n",
      "EPOCH: [74/100] train loss: 0.3981 train acc: 0.8806 val loss: 0.3781 val acc: 0.885260\n",
      "EPOCH: [75/100] train loss: 0.3906 train acc: 0.8810 val loss: 0.3731 val acc: 0.886097\n",
      "EPOCH: [76/100] train loss: 0.4159 train acc: 0.8758 val loss: 0.3723 val acc: 0.886097\n",
      "EPOCH: [77/100] train loss: 0.3861 train acc: 0.8817 val loss: 0.3763 val acc: 0.884422\n",
      "EPOCH: [78/100] train loss: 0.3816 train acc: 0.8819 val loss: 0.3797 val acc: 0.885260\n",
      "EPOCH: [79/100] train loss: 0.3916 train acc: 0.8798 val loss: 0.3729 val acc: 0.884422\n",
      "EPOCH: [80/100] train loss: 0.3973 train acc: 0.8800 val loss: 0.3801 val acc: 0.884422\n",
      "EPOCH: [81/100] train loss: 0.3977 train acc: 0.8800 val loss: 0.3737 val acc: 0.885260\n",
      "EPOCH: [82/100] train loss: 0.3869 train acc: 0.8823 val loss: 0.3750 val acc: 0.886097\n",
      "EPOCH: [83/100] train loss: 0.3827 train acc: 0.8838 val loss: 0.3898 val acc: 0.883585\n",
      "EPOCH: [84/100] train loss: 0.3944 train acc: 0.8792 val loss: 0.4117 val acc: 0.875209\n",
      "EPOCH: [85/100] train loss: 0.4061 train acc: 0.8775 val loss: 0.3940 val acc: 0.883585\n",
      "EPOCH: [86/100] train loss: 0.3859 train acc: 0.8823 val loss: 0.3885 val acc: 0.883585\n",
      "EPOCH: [87/100] train loss: 0.3876 train acc: 0.8815 val loss: 0.3746 val acc: 0.884422\n",
      "EPOCH: [88/100] train loss: 0.3967 train acc: 0.8790 val loss: 0.3756 val acc: 0.884422\n",
      "EPOCH: [89/100] train loss: 0.3851 train acc: 0.8823 val loss: 0.3913 val acc: 0.883585\n",
      "EPOCH: [90/100] train loss: 0.3857 train acc: 0.8819 val loss: 0.3823 val acc: 0.885260\n",
      "EPOCH: [91/100] train loss: 0.3785 train acc: 0.8821 val loss: 0.3800 val acc: 0.881910\n",
      "EPOCH: [92/100] train loss: 0.3984 train acc: 0.8785 val loss: 0.3878 val acc: 0.884422\n",
      "EPOCH: [93/100] train loss: 0.3791 train acc: 0.8819 val loss: 0.3625 val acc: 0.882747\n",
      "EPOCH: [94/100] train loss: 0.3835 train acc: 0.8819 val loss: 0.3628 val acc: 0.886935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: [95/100] train loss: 0.3858 train acc: 0.8823 val loss: 0.3853 val acc: 0.883585\n",
      "EPOCH: [96/100] train loss: 0.3937 train acc: 0.8798 val loss: 0.3722 val acc: 0.885260\n",
      "EPOCH: [97/100] train loss: 0.3763 train acc: 0.8838 val loss: 0.3626 val acc: 0.885260\n",
      "EPOCH: [98/100] train loss: 0.3965 train acc: 0.8796 val loss: 0.3757 val acc: 0.885260\n",
      "EPOCH: [99/100] train loss: 0.3898 train acc: 0.8819 val loss: 0.3728 val acc: 0.886935\n",
      "EPOCH: [100/100] train loss: 0.3916 train acc: 0.8827 val loss: 0.3712 val acc: 0.886097\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, max_epoch+1):\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model = model.train()\n",
    "    # Training\n",
    "    for train_data in train_dataloader:\n",
    "        train_labels = train_data.y\n",
    "        x = train_data.x.float().to(device)\n",
    "        edge_index = train_data.edge_index.to(device)\n",
    "        batch = train_data.batch.to(device)\n",
    "        edge_attr = None\n",
    "        train_labels = train_data.y.long().to(device).view(-1)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        train_scores = model(x, edge_index, batch, edge_attr)\n",
    "        loss = loss_function(train_scores, train_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predict = torch.max(train_scores.data, 1)\n",
    "        correct += (predict == train_labels).sum().item()\n",
    "        total += train_labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / len(train_dataloader)\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # Check model validation \n",
    "    model = model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_scores = model(val_data, val_edge_index, val_batch, val_edge_attr)\n",
    "        val_loss = loss_function(val_scores, val_labels)\n",
    "\n",
    "        bi_scores = torch.argmax(val_scores, dim=1).to(device).numpy()\n",
    "        y_val_scores = val_labels.to(device).numpy()\n",
    "        val_acc = accuracy_score(y_val_scores, bi_scores)\n",
    "    \n",
    "    print(f'EPOCH: [{epoch}/{max_epoch}] train loss: {train_loss:.4f} train acc: {train_acc:.4f} val loss: {val_loss:.4f} val acc: {val_acc:4f}')\n",
    "#     Export model\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(model.state_dict(), f\"./{model_dir}/gcn_{epoch}.mdl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3cd2c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9066191636977311\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "                       normal       0.88      0.99      0.93      3505\n",
      "ixnetwork-bgp-hijacking-start       0.97      0.71      0.82       377\n",
      "ixnetwork-bgp-injection-start       0.98      1.00      0.99       329\n",
      "                    node-down       1.00      1.00      1.00       140\n",
      "               interface-down       0.97      0.61      0.75       157\n",
      "            packet-loss-delay       0.98      0.64      0.77       825\n",
      "\n",
      "                     accuracy                           0.91      5333\n",
      "                    macro avg       0.96      0.82      0.88      5333\n",
      "                 weighted avg       0.91      0.91      0.90      5333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(model_dir, \"gcn_100.mdl\")\n",
    "path = '../dataset/test/network'\n",
    "dataset = NetworkMetricsWithTopologyDataset(path)\n",
    "\n",
    "input_dim = dataset[0].x.shape[-1]\n",
    "output_dim = len(events.keys())\n",
    "\n",
    "test_dataloader = DataLoader(dataset, batch_size=len(dataset))\n",
    "test_data = iter(test_dataloader).next()\n",
    "x = test_data.x.float().to(device)\n",
    "edge_index = test_data.edge_index.to(device)\n",
    "batch = test_data.batch.to(device)\n",
    "edge_attr = None\n",
    "test_label = test_data.y.long().to(device).view(-1)\n",
    "\n",
    "model = GCNClassifier(input_dim, output_dim).to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model = model.eval()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "with torch.no_grad():\n",
    "    test_scores = model(x, edge_index, batch, edge_attr)\n",
    "    loss = loss_function(test_scores, test_label)\n",
    "    bi_scores = torch.argmax(test_scores, dim=1).to('cpu').numpy()\n",
    "    y_test_scores = test_label.to('cpu').numpy()\n",
    "print(accuracy_score(y_test_scores, bi_scores))\n",
    "print(classification_report(y_test_scores, bi_scores, target_names=list(events.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb1554f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
