{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gnn.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPBDEWaEsnAmh+Q292KG+0U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oakeshott/lsm-intern-2022/blob/master/jupyter/gnn-gc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TSZyh6odRTO",
        "outputId": "7781c0e5-caec-41ae-80ec-9f81c98d4467"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lsm-intern-2022'...\n",
            "remote: Enumerating objects: 50660, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 50660 (delta 23), reused 36 (delta 15), pack-reused 50616\u001b[K\n",
            "Receiving objects: 100% (50660/50660), 50.89 MiB | 27.35 MiB/s, done.\n",
            "Resolving deltas: 100% (50574/50574), done.\n",
            "Checking out files: 100% (22641/22641), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.9.1\n",
            "  Downloading torch-1.9.1-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 6.1 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.10.1\n",
            "  Downloading torchvision-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.1 MB 49.0 MB/s \n",
            "\u001b[?25hCollecting torchaudio==0.9.1\n",
            "  Downloading torchaudio-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 37.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.1) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.1) (1.21.6)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.1) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.1+cu113\n",
            "    Uninstalling torchvision-0.13.1+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.1+cu113\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.12.1+cu113\n",
            "    Uninstalling torchaudio-0.12.1+cu113:\n",
            "      Successfully uninstalled torchaudio-0.12.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.9.1 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.1 torchaudio-0.9.1 torchvision-0.10.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.9.1+cpu.html\n",
            "Collecting torch-scatter==2.0.7\n",
            "  Downloading https://data.pyg.org/whl/torch-1.9.0%2Bcpu/torch_scatter-2.0.7-cp37-cp37m-linux_x86_64.whl (280 kB)\n",
            "\u001b[K     |████████████████████████████████| 280 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting torch-sparse==0.6.10\n",
            "  Downloading https://data.pyg.org/whl/torch-1.9.0%2Bcpu/torch_sparse-0.6.10-cp37-cp37m-linux_x86_64.whl (519 kB)\n",
            "\u001b[K     |████████████████████████████████| 519 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting torch-cluster==1.5.9\n",
            "  Downloading https://data.pyg.org/whl/torch-1.9.0%2Bcpu/torch_cluster-1.5.9-cp37-cp37m-linux_x86_64.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 35.0 MB/s \n",
            "\u001b[?25hCollecting torch-spline-conv==1.2.1\n",
            "  Downloading https://data.pyg.org/whl/torch-1.9.0%2Bcpu/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 35.3 MB/s \n",
            "\u001b[?25hCollecting torch-geometric==2.0.1\n",
            "  Downloading torch_geometric-2.0.1.tar.gz (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse==0.6.10) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.1) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.1) (4.64.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.1) (2.6.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.1) (1.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.1) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.1) (1.3.5)\n",
            "Collecting rdflib\n",
            "  Downloading rdflib-6.2.0-py3-none-any.whl (500 kB)\n",
            "\u001b[K     |████████████████████████████████| 500 kB 61.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.1) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.1) (2.11.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.1) (3.0.9)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.1) (6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric==2.0.1) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric==2.0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric==2.0.1) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric==2.0.1) (1.15.0)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 671 kB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric==2.0.1) (4.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric==2.0.1) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric==2.0.1) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric==2.0.1) (4.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==2.0.1) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==2.0.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==2.0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==2.0.1) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric==2.0.1) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric==2.0.1) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.1-py3-none-any.whl size=513820 sha256=d37543d0ff061b7f7338237c671f639abf9f12447047ec9175fc86b7625eb05b\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/3d/42/20589db73c66b5109fb93a0c5743edfd6ab5ca820a52afacfc\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, yacs, rdflib, torch-spline-conv, torch-sparse, torch-scatter, torch-geometric, torch-cluster\n",
            "Successfully installed isodate-0.6.1 rdflib-6.2.0 torch-cluster-1.5.9 torch-geometric-2.0.1 torch-scatter-2.0.7 torch-sparse-0.6.10 torch-spline-conv-1.2.1 yacs-0.1.8\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (2.6.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=2b64f40886cce0becb3ad838d081e3e4e8e2d91b126b2123c7605c38575e69cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!git clone https://github.com/oakeshott/lsm-intern-2022\n",
        "!pip install torch==1.9.1 torchvision==0.10.1 torchaudio==0.9.1\n",
        "!pip install torch-scatter==2.0.7 torch-sparse==0.6.10 torch-cluster==1.5.9 torch-spline-conv==1.2.1 torch-geometric==2.0.1 -f https://data.pyg.org/whl/torch-1.9.1+cpu.html\n",
        "!pip install networkx pandas numpy sklearn joblib tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from torch.utils.data import random_split, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import joblib\n",
        "from torch_geometric.data import Dataset, InMemoryDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.utils import from_networkx, train_test_split_edges\n",
        "from torch_geometric.nn import global_add_pool, GCNConv\n",
        "import networkx as nx"
      ],
      "metadata": {
        "id": "-dwa9_u2dSn7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NetworkMetricsWithTopologyDataset(Dataset):\n",
        "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
        "        super().__init__(root, transform, pre_transform, pre_filter)\n",
        "#         self.data_dir = \"../dataset/train/network\"\n",
        "#         self.processed_dir = '/tmp/'\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return [filename for filename in sorted(os.listdir(self.raw_dir))]\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "#         data_size = 5969\n",
        "#         data_size = 5333\n",
        "#         return [f'data_{i}.pt' for i in range(data_size)]\n",
        "        return [i  for i in sorted(os.listdir(self.processed_dir)) if 'data' in i]\n",
        "\n",
        "    def process(self):\n",
        "        idx = 0\n",
        "        for raw_path in self.raw_paths:\n",
        "            # Read data from `raw_path`.\n",
        "            g = nx.read_gpickle(raw_path)\n",
        "            for n in g.nodes():\n",
        "                label = g.nodes()[n]['label']\n",
        "                del g.nodes()[n]['label']\n",
        "            data = from_networkx(g)\n",
        "            data.y =  torch.tensor(label)\n",
        "            data.num_nodes = len(g.nodes())\n",
        "            data.edge_attr = []\n",
        "            if self.pre_filter is not None and not self.pre_filter(data):\n",
        "                continue\n",
        "\n",
        "            if self.pre_transform is not None:\n",
        "                data = self.pre_transform(data)\n",
        "\n",
        "            torch.save(data, os.path.join(self.processed_dir, f'data_{idx}.pt'))\n",
        "            idx += 1\n",
        "\n",
        "    def len(self):\n",
        "        return len(self.processed_file_names)\n",
        "\n",
        "    def get(self, idx):\n",
        "        data = torch.load(os.path.join(self.processed_dir, f'data_{idx}.pt'))\n",
        "        return data"
      ],
      "metadata": {
        "id": "0iK88Eq1da2W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(GCNClassifier, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        hidden_dim = 128\n",
        "        \n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(hidden_dim, self.output_dim),\n",
        "        )\n",
        "        \n",
        "        self.gcn1 = GCNConv(self.input_dim, hidden_dim)\n",
        "        self.gcn2 = GCNConv(hidden_dim, hidden_dim)\n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        \n",
        "    def forward(self, x, edge_index, batch, edge_attr):\n",
        "        x = self.gcn1(x, edge_index, edge_attr)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.gcn2(x, edge_index, edge_attr)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        return self.linear(global_add_pool(x, batch))"
      ],
      "metadata": {
        "id": "uxRFBH04dmPB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 1\n",
        "batchsize = 16\n",
        "max_epoch = 100\n",
        "device = 'cpu'\n",
        "path = \"/content/lsm-intern-2022/dataset/train/network\"\n",
        "model_dir = \"models/gcn\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "metrics = [\"cpu-util\", \"tx-pps\", \"rx-pps\", \"network-incoming-packets-rate\", \"network-outgoing-packets-rate\", \"prefix-activity-received-current-prefixes\"]\n",
        "events = {\n",
        "    'normal': 0,\n",
        "    'ixnetwork-bgp-hijacking-start': 1,\n",
        "    'ixnetwork-bgp-injection-start': 2,\n",
        "    'node-down': 3,\n",
        "    'interface-down': 4,\n",
        "    'packet-loss-delay': 5,\n",
        "}\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "dataset = NetworkMetricsWithTopologyDataset(path)"
      ],
      "metadata": {
        "id": "Ya1otsdadpxe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [dataset[i].y for i in range(len(dataset))]\n",
        "train_indices, val_indices = train_test_split(\n",
        "    list(range(len(dataset))),\n",
        "    test_size=0.2,\n",
        "    stratify=labels,\n",
        "    random_state=seed,\n",
        ")"
      ],
      "metadata": {
        "id": "-42ib3nzdxIg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset[train_indices]\n",
        "train_size = len(train_dataset)\n",
        "val_dataset = dataset[val_indices]\n",
        "val_size = len(val_dataset)"
      ],
      "metadata": {
        "id": "w0GEY8V-dzbq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=batchsize)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=val_size)\n",
        "\n",
        "\n",
        "input_dim = train_dataset[0].x.shape[-1]\n",
        "output_dim = len(events.keys())\n",
        "model =GCNClassifier(input_dim, output_dim).to(device)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "\n",
        "val_data = iter(val_dataloader).next()\n",
        "val_batch = val_data.batch.to(device)\n",
        "val_edge_index = val_data.edge_index.to(device)\n",
        "val_edge_attr = None\n",
        "val_labels = val_data.y.long().to(device).view(-1)\n",
        "val_data = val_data.x.float().to(device)"
      ],
      "metadata": {
        "id": "WivdThGad0rE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, max_epoch+1):\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model = model.train()\n",
        "    # Training\n",
        "    for train_data in train_dataloader:\n",
        "        train_labels = train_data.y\n",
        "        x = train_data.x.float().to(device)\n",
        "        edge_index = train_data.edge_index.to(device)\n",
        "        batch = train_data.batch.to(device)\n",
        "        edge_attr = None\n",
        "        train_labels = train_data.y.long().to(device).view(-1)\n",
        "        \n",
        "        model.zero_grad()\n",
        "        train_scores = model(x, edge_index, batch, edge_attr)\n",
        "        loss = loss_function(train_scores, train_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        _, predict = torch.max(train_scores.data, 1)\n",
        "        correct += (predict == train_labels).sum().item()\n",
        "        total += train_labels.size(0)\n",
        "\n",
        "    train_loss = running_loss / len(train_dataloader)\n",
        "    train_acc = correct / total\n",
        "\n",
        "    # Check model validation \n",
        "    model = model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_scores = model(val_data, val_edge_index, val_batch, val_edge_attr)\n",
        "        val_loss = loss_function(val_scores, val_labels)\n",
        "\n",
        "        bi_scores = torch.argmax(val_scores, dim=1).to(device).numpy()\n",
        "        y_val_scores = val_labels.to(device).numpy()\n",
        "        val_acc = accuracy_score(y_val_scores, bi_scores)\n",
        "    \n",
        "    print(f'EPOCH: [{epoch}/{max_epoch}] train loss: {train_loss:.4f} train acc: {train_acc:.4f} val loss: {val_loss:.4f} val acc: {val_acc:4f}')\n",
        "#     Export model\n",
        "    if epoch % 10 == 0:\n",
        "        torch.save(model.state_dict(), f\"./{model_dir}/gcn_{epoch}.mdl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvEGhj1dd2Ok",
        "outputId": "0cd6b9c9-13af-41c4-f0f3-2e4808a8d4a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: [1/100] train loss: 0.8444 train acc: 0.7401 val loss: 0.6900 val acc: 0.782245\n",
            "EPOCH: [2/100] train loss: 0.6983 train acc: 0.7964 val loss: 0.6073 val acc: 0.824121\n",
            "EPOCH: [3/100] train loss: 0.6508 train acc: 0.8184 val loss: 0.5724 val acc: 0.829983\n",
            "EPOCH: [4/100] train loss: 0.6243 train acc: 0.8220 val loss: 0.5319 val acc: 0.835846\n",
            "EPOCH: [5/100] train loss: 0.5766 train acc: 0.8318 val loss: 0.4940 val acc: 0.848409\n",
            "EPOCH: [6/100] train loss: 0.5445 train acc: 0.8477 val loss: 0.4564 val acc: 0.862647\n",
            "EPOCH: [7/100] train loss: 0.5126 train acc: 0.8501 val loss: 0.4386 val acc: 0.867672\n",
            "EPOCH: [8/100] train loss: 0.4947 train acc: 0.8580 val loss: 0.4289 val acc: 0.865159\n",
            "EPOCH: [9/100] train loss: 0.4882 train acc: 0.8595 val loss: 0.4268 val acc: 0.871022\n",
            "EPOCH: [10/100] train loss: 0.4812 train acc: 0.8595 val loss: 0.4545 val acc: 0.857621\n",
            "EPOCH: [11/100] train loss: 0.4723 train acc: 0.8616 val loss: 0.4216 val acc: 0.871022\n",
            "EPOCH: [12/100] train loss: 0.4683 train acc: 0.8624 val loss: 0.4207 val acc: 0.870184\n",
            "EPOCH: [13/100] train loss: 0.4552 train acc: 0.8647 val loss: 0.4188 val acc: 0.873534\n",
            "EPOCH: [14/100] train loss: 0.4506 train acc: 0.8674 val loss: 0.4208 val acc: 0.861809\n",
            "EPOCH: [15/100] train loss: 0.4449 train acc: 0.8691 val loss: 0.3954 val acc: 0.878559\n",
            "EPOCH: [16/100] train loss: 0.4467 train acc: 0.8664 val loss: 0.3894 val acc: 0.877722\n",
            "EPOCH: [17/100] train loss: 0.4347 train acc: 0.8683 val loss: 0.3898 val acc: 0.882747\n",
            "EPOCH: [18/100] train loss: 0.4363 train acc: 0.8683 val loss: 0.3893 val acc: 0.878559\n",
            "EPOCH: [19/100] train loss: 0.4260 train acc: 0.8727 val loss: 0.3858 val acc: 0.881072\n",
            "EPOCH: [20/100] train loss: 0.4403 train acc: 0.8674 val loss: 0.3897 val acc: 0.877722\n",
            "EPOCH: [21/100] train loss: 0.4207 train acc: 0.8756 val loss: 0.3798 val acc: 0.882747\n",
            "EPOCH: [22/100] train loss: 0.4224 train acc: 0.8731 val loss: 0.3770 val acc: 0.880235\n",
            "EPOCH: [23/100] train loss: 0.4285 train acc: 0.8714 val loss: 0.3810 val acc: 0.881910\n",
            "EPOCH: [24/100] train loss: 0.4220 train acc: 0.8723 val loss: 0.4104 val acc: 0.873534\n",
            "EPOCH: [25/100] train loss: 0.4216 train acc: 0.8725 val loss: 0.3788 val acc: 0.883585\n",
            "EPOCH: [26/100] train loss: 0.4206 train acc: 0.8723 val loss: 0.3797 val acc: 0.882747\n",
            "EPOCH: [27/100] train loss: 0.4134 train acc: 0.8748 val loss: 0.3755 val acc: 0.881910\n",
            "EPOCH: [28/100] train loss: 0.4208 train acc: 0.8748 val loss: 0.3981 val acc: 0.877722\n",
            "EPOCH: [29/100] train loss: 0.4178 train acc: 0.8727 val loss: 0.3771 val acc: 0.884422\n",
            "EPOCH: [30/100] train loss: 0.4099 train acc: 0.8750 val loss: 0.3694 val acc: 0.885260\n",
            "EPOCH: [31/100] train loss: 0.4120 train acc: 0.8748 val loss: 0.3713 val acc: 0.884422\n",
            "EPOCH: [32/100] train loss: 0.4087 train acc: 0.8777 val loss: 0.4230 val acc: 0.876884\n",
            "EPOCH: [33/100] train loss: 0.4151 train acc: 0.8766 val loss: 0.3818 val acc: 0.877722\n",
            "EPOCH: [34/100] train loss: 0.4039 train acc: 0.8766 val loss: 0.3698 val acc: 0.885260\n",
            "EPOCH: [35/100] train loss: 0.4107 train acc: 0.8750 val loss: 0.3724 val acc: 0.886097\n",
            "EPOCH: [36/100] train loss: 0.4014 train acc: 0.8800 val loss: 0.3767 val acc: 0.884422\n",
            "EPOCH: [37/100] train loss: 0.4078 train acc: 0.8760 val loss: 0.3816 val acc: 0.881910\n",
            "EPOCH: [38/100] train loss: 0.4153 train acc: 0.8748 val loss: 0.3691 val acc: 0.885260\n",
            "EPOCH: [39/100] train loss: 0.4057 train acc: 0.8773 val loss: 0.4321 val acc: 0.866834\n",
            "EPOCH: [40/100] train loss: 0.4112 train acc: 0.8758 val loss: 0.3711 val acc: 0.883585\n",
            "EPOCH: [41/100] train loss: 0.4115 train acc: 0.8766 val loss: 0.3796 val acc: 0.885260\n",
            "EPOCH: [42/100] train loss: 0.4067 train acc: 0.8775 val loss: 0.3706 val acc: 0.886097\n",
            "EPOCH: [43/100] train loss: 0.3937 train acc: 0.8817 val loss: 0.3753 val acc: 0.882747\n",
            "EPOCH: [44/100] train loss: 0.4043 train acc: 0.8787 val loss: 0.3716 val acc: 0.882747\n",
            "EPOCH: [45/100] train loss: 0.4050 train acc: 0.8773 val loss: 0.3713 val acc: 0.885260\n",
            "EPOCH: [46/100] train loss: 0.3979 train acc: 0.8777 val loss: 0.3682 val acc: 0.886097\n",
            "EPOCH: [47/100] train loss: 0.3985 train acc: 0.8790 val loss: 0.3786 val acc: 0.883585\n",
            "EPOCH: [48/100] train loss: 0.3980 train acc: 0.8796 val loss: 0.3840 val acc: 0.880235\n",
            "EPOCH: [49/100] train loss: 0.4014 train acc: 0.8777 val loss: 0.3653 val acc: 0.886097\n",
            "EPOCH: [50/100] train loss: 0.3997 train acc: 0.8781 val loss: 0.3865 val acc: 0.877722\n",
            "EPOCH: [51/100] train loss: 0.4137 train acc: 0.8754 val loss: 0.3666 val acc: 0.884422\n",
            "EPOCH: [52/100] train loss: 0.4040 train acc: 0.8790 val loss: 0.3898 val acc: 0.878559\n",
            "EPOCH: [53/100] train loss: 0.3921 train acc: 0.8817 val loss: 0.3718 val acc: 0.886097\n",
            "EPOCH: [54/100] train loss: 0.3971 train acc: 0.8800 val loss: 0.3767 val acc: 0.883585\n",
            "EPOCH: [55/100] train loss: 0.4025 train acc: 0.8792 val loss: 0.3951 val acc: 0.879397\n",
            "EPOCH: [56/100] train loss: 0.4122 train acc: 0.8769 val loss: 0.3720 val acc: 0.884422\n",
            "EPOCH: [57/100] train loss: 0.3970 train acc: 0.8792 val loss: 0.3702 val acc: 0.885260\n",
            "EPOCH: [58/100] train loss: 0.3901 train acc: 0.8810 val loss: 0.3760 val acc: 0.884422\n",
            "EPOCH: [59/100] train loss: 0.3914 train acc: 0.8800 val loss: 0.3741 val acc: 0.885260\n",
            "EPOCH: [60/100] train loss: 0.3955 train acc: 0.8804 val loss: 0.3762 val acc: 0.885260\n",
            "EPOCH: [61/100] train loss: 0.3900 train acc: 0.8806 val loss: 0.3727 val acc: 0.885260\n",
            "EPOCH: [62/100] train loss: 0.3933 train acc: 0.8794 val loss: 0.3785 val acc: 0.882747\n",
            "EPOCH: [63/100] train loss: 0.3959 train acc: 0.8790 val loss: 0.3735 val acc: 0.886097\n",
            "EPOCH: [64/100] train loss: 0.3934 train acc: 0.8808 val loss: 0.3777 val acc: 0.885260\n",
            "EPOCH: [65/100] train loss: 0.3949 train acc: 0.8796 val loss: 0.3726 val acc: 0.886097\n",
            "EPOCH: [66/100] train loss: 0.3869 train acc: 0.8815 val loss: 0.3679 val acc: 0.886097\n",
            "EPOCH: [67/100] train loss: 0.4148 train acc: 0.8748 val loss: 0.3772 val acc: 0.885260\n",
            "EPOCH: [68/100] train loss: 0.3918 train acc: 0.8808 val loss: 0.3806 val acc: 0.885260\n",
            "EPOCH: [69/100] train loss: 0.3910 train acc: 0.8815 val loss: 0.3700 val acc: 0.885260\n",
            "EPOCH: [70/100] train loss: 0.3851 train acc: 0.8817 val loss: 0.3790 val acc: 0.884422\n",
            "EPOCH: [71/100] train loss: 0.3866 train acc: 0.8810 val loss: 0.3739 val acc: 0.884422\n",
            "EPOCH: [72/100] train loss: 0.4125 train acc: 0.8752 val loss: 0.3833 val acc: 0.881910\n",
            "EPOCH: [73/100] train loss: 0.4021 train acc: 0.8766 val loss: 0.3852 val acc: 0.884422\n",
            "EPOCH: [74/100] train loss: 0.3896 train acc: 0.8808 val loss: 0.3828 val acc: 0.885260\n",
            "EPOCH: [75/100] train loss: 0.3944 train acc: 0.8810 val loss: 0.3700 val acc: 0.886097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = os.path.join(model_dir, \"gcn_100.mdl\")\n",
        "path = '/content/lsm-intern-2022/dataset/test/network'\n",
        "dataset = NetworkMetricsWithTopologyDataset(path)\n",
        "\n",
        "input_dim = dataset[0].x.shape[-1]\n",
        "output_dim = len(events.keys())\n",
        "\n",
        "test_dataloader = DataLoader(dataset, batch_size=len(dataset))\n",
        "test_data = iter(test_dataloader).next()\n",
        "x = test_data.x.float().to(device)\n",
        "edge_index = test_data.edge_index.to(device)\n",
        "batch = test_data.batch.to(device)\n",
        "edge_attr = None\n",
        "test_label = test_data.y.long().to(device).view(-1)\n",
        "\n",
        "model = GCNClassifier(input_dim, output_dim).to(device)\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model = model.eval()\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "with torch.no_grad():\n",
        "    test_scores = model(x, edge_index, batch, edge_attr)\n",
        "    loss = loss_function(test_scores, test_label)\n",
        "    bi_scores = torch.argmax(test_scores, dim=1).to('cpu').numpy()\n",
        "    y_test_scores = test_label.to('cpu').numpy()\n",
        "print(accuracy_score(y_test_scores, bi_scores))\n",
        "print(classification_report(y_test_scores, bi_scores, target_names=list(events.keys())))"
      ],
      "metadata": {
        "id": "f4OEK3jnd4Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_qJb1Fncd9aU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}